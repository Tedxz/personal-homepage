---
---
@inproceedings{aaai23cale,
  abbr        = {AAAI},
  bibtex_show = {true},
  selected    = {true},
  author      = {Sun, Hui and Xie, Zheng and Li, Xin-Ye and Li, Ming},
  booktitle   = {The 37rd AAAI Conference on Artificial Intelligence},
  title       = {Cooperative and Adversarial Learning: Co-Enhancing Discriminability and Transferability in Domain Adaptation},
  year        = {2023},
  pdf         = {CAT-preprint.pdf},
  abstract    = {We propose CALE framework to unify and enhance the two main objectives of domain adaptation, i.e., discriminability and transferability. To achieve this, CALE swap the cooperative examples of the two objectives to make the learning of discriminability and transferability help each other, and uses adversarial examples for the two objectives themselves to enhance their robustness. The framework can be applied to enhance current domain adaptation approaches, and outperforms existing state-of-the-art approaches.},
  image       = {assets/img/pub_img/5.png}
}


@inproceedings{aaai23,
  abbr        = {AAAI},
  bibtex_show = {true},
  selected    = {true},
  author      = {Xie, Zheng and Sun, Hui and Li, Ming},
  booktitle   = {The 37rd AAAI Conference on Artificial Intelligence},
  title       = {Semi-Supervised Learning with Support Isolation by Small-Paced Self-Training},
  year        = {2023},
  pdf         = {LMU-preprint.pdf},
  abstract    = {In this paper, we address a special scenario of semi-supervised learning, where the label missing is caused by a preceding ﬁltering mechanism, i.e., an instance can enter a subsequent process in which its label is revealed if and only if it passes the ﬁltering mechanism. The rejected instances are prohibited to enter the subsequent labeling process due to economical or ethical reasons, making the support of the labeled and unlabeled distributions isolated from each other. In this case, classical semi-supervised learning approaches are prone to fail. We propose a SmallPaced Self-Training framework, which iteratively discovers labeled and unlabeled instance subspaces with bounded Wasserstein distance. We theoretically prove that such a framework may achieve provably low error on the pseudo labels during learning, and validate the approach through experiments.},
  image       = {assets/img/pub_img/4.png}
}

@inproceedings{ijcai18,
  abbr        = {IJCAI},
  bibtex_show = {true},
  selected    = {true},
  author      = {Xie, Zheng and Li, Ming},
  booktitle   = {The 27th International Joint Conference on Artificial Intelligence},
  title       = {Cutting the Software Building Efforts in Continuous Integration by Semi-Supervised Online AUC Optimization},
  year        = {2018},
  pdf         = {ijcai18-xiez.pdf},
  abstract    = {In this paper, we propose a semi-supervised online AUC optimization algorithm, namely SOLA. This algorithm is suitable for tasks that suffers from streaming data, label scarce, and imbalance. The algorithm is used for solving build outcome prediction in software continuous integration, and achieves superior performance.},
  code        = {assets/code/sola.py.zip},
  image       = {assets/img/pub_img/3.png}
}

@inproceedings{aaai18,
  abbr        = {AAAI},
  bibtex_show = {true},
  selected    = {true},
  author      = {Xie, Zheng and Li, Ming},
  booktitle   = {The 32nd AAAI Conference on Artificial Intelligence},
  title       = {Semi-Supervised AUC Optimization without Guessing Labels of Unlabeled Data},
  year        = {2018},
  abstract    = {We prove the theoretical property of AUC optimization under semi-supervised learning and positive-unlabeled learning scenarios, and propose a simple yet effective algorithm for semi-supervised and positive-unlabeled AUC optimization. Our algorithm outperforms elaborated approaches on semi-supervised and positive-unlabeled AUC optimization approaches.},
  pdf         = {aaai18-xiez.pdf},
  code        = {assets/code/sola.py.zip},
  image       = {assets/img/pub_img/2.png}
}

@article{jos,
  abbr        = {JOS},
  bibtex_show = {true},
  selected    = {true},
  author      = {Zheng Xie and Ming Li},
  journal     = {Journal of Software},
  number      = {11},
  title       = {Cost-Sensitive Margin Distribution Optimization for Software Bug Localization},
  volume      = {28},
  year        = {2017},
  pdf         = {jos2811-xiez.pdf},
  abstract    = {Software bug localization problem suffers from data imbalance and heterogeneous code and natural language structure. To tackle this problem, we propose cost-sensitive margin distribution optimization method to enhance the classification tasks under imbalanced scenario, and design a network architecture for processing programming and natural language. Experimental results validates the effectiveness of our method.},
  image       = {assets/img/pub_img/1.png}
}
@inproceedings{ccml17,
  abbr        = {CCML},
  bibtex_show = {true},
  selected    = {false},
  author      = {Zheng Xie and Ming Li},
  booktitle   = {China Conference on Machine Learning},
  title       = {Cost-Sensitive Margin Distribution Optimization for Software Bug Localization},
  year        = {2017},
  pdf         = {jos2811-xiez.pdf},
  abstract    = {Software bug localization problem suffers from data imbalance and heterogeneous code and natural language structure. To tackle this problem, we propose cost-sensitive margin distribution optimization method to enhance the classification tasks under imbalanced scenario, and design a network architecture for processing programming and natural language. Experimental results validates the effectiveness of our method.},
  image       = {assets/img/pub_img/1.png}
}
@inproceedings{icmc17,
  abbr        = {ICMC},
  bibtex_show = {true},
  selected    = {true},
  author      = {Ru Wen and Zheng Xie and Kai Chen and Ruoxuan Guo and Kuan Xu and Wenmin Huang and Jiyuan Tian and Jiang Wu},
  booktitle   = {The 43rd International Computer Music Conference},
  title       = {Music Style Analysis among Haydn, Mozart and Beethoven: an Unsupervised Machine Learning Approach},
  year        = {2017},
  pdf         = {icmc17-xiez.pdf},
  abstract    = {We propose an unsupervised music analysis method. We propose a feature extraction method for extracting consecutive note pitch patterns, and use clustering methods for mining the music styles. We apply our method on new built corpus of Haydn, Mozart, and Beethoven. Our discovered pattern fits the Implication-Realization theory, which confirms the validity of our approach.},
  image       = {assets/img/pub_img/0.png}
}
